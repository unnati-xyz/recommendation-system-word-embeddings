{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import linalg\n",
    "import pickle\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "tokenizer = RegexpTokenizer(r'\\w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stop_words = []\n",
    "with open('stopwords', 'rb') as fp:\n",
    "    stop_words = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cleaned_tags = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " with open('data/artist_tags.csv', 'r') as inpFile:\n",
    "        lines = inpFile.readlines()\n",
    "        for line in lines:\n",
    "            if line.isspace() is False:\n",
    "                tags = tokenizer.tokenize(line)\n",
    "                final_tags = []\n",
    "                if len(tags) > 0:\n",
    "                    for tag in tags:\n",
    "                        if len(tag) > 1 and tag not in stop_words:\n",
    "                            final_tags.append(tag.lower())\n",
    "                    if len(final_tags) > 0:\n",
    "                        cleaned_tags.append(list(set(final_tags)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99450"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cleaned_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(cleaned_tags_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['punk',\n",
       " 'steam',\n",
       " 'surreal',\n",
       " 'victorian',\n",
       " 'black',\n",
       " 'collage',\n",
       " 'sepia',\n",
       " 'steampunk',\n",
       " 'vintage',\n",
       " 'cephalopod',\n",
       " 'gear',\n",
       " 'octopus',\n",
       " 'tentacles',\n",
       " 'lovecraft',\n",
       " 'cool',\n",
       " 'cthulhu',\n",
       " 'gentleman',\n",
       " 'character',\n",
       " 'squid',\n",
       " 'animal',\n",
       " 'digital']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_tags[51961]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word2vec_sg = Word2Vec(sentences=cleaned_tags, size=100, window=5, min_count=1, workers=4, sg=1, iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word2vec_sg.save(\"word2vec_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w2v = Word2Vec.load(\"word2vec_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('onelinedrawing', 0.927032470703125),\n",
       " ('thenbh', 0.9215524792671204),\n",
       " ('antemasque', 0.9204072952270508),\n",
       " ('wpsiatwin', 0.9184987545013428),\n",
       " ('understatement', 0.9125391244888306),\n",
       " ('altrock', 0.9112753868103027),\n",
       " ('brianstorm', 0.9094448089599609),\n",
       " ('no1', 0.9080705642700195),\n",
       " ('egipt', 0.9079245328903198),\n",
       " ('hampstead', 0.9073182940483093)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.most_similar(positive=['arctic', 'mardy', 'oriques'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('antionette', 0.8257869482040405),\n",
       " ('bastilledan', 0.821168065071106),\n",
       " ('jese', 0.8099668622016907),\n",
       " ('subteranian', 0.809721827507019),\n",
       " ('kigns', 0.8039277791976929),\n",
       " ('jme', 0.8032917380332947),\n",
       " ('kygo', 0.8004037737846375),\n",
       " ('parting', 0.7984482049942017),\n",
       " ('feelin', 0.7982733249664307),\n",
       " ('nbh', 0.7981569170951843)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.most_similar(positive=['linkin', 'awards'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now we can predict a tag given other tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Given a search query, lets try and find the right products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = []\n",
    "a.append(w2v['pikachu'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b = w2v['pokemon']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.91971552], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(a, b)/linalg.norm(a)/linalg.norm(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "product_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for key,product in enumerate(cleaned_tags):\n",
    "    if len(product) == 0:\n",
    "        print(product, key)\n",
    "    feature_vector = np.zeros((100,), dtype=\"float32\")\n",
    "    nwords = len(product)\n",
    "    for token in product:\n",
    "        feature_vector = np.add(feature_vector, w2v[token])\n",
    "    \n",
    "    feature_vector = np.divide(feature_vector, nwords)\n",
    "    product_data.append({'tags':product, 'vector':feature_vector})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['punk',\n",
       " 'steam',\n",
       " 'surreal',\n",
       " 'victorian',\n",
       " 'black',\n",
       " 'collage',\n",
       " 'sepia',\n",
       " 'steampunk',\n",
       " 'vintage',\n",
       " 'cephalopod',\n",
       " 'gear',\n",
       " 'octopus',\n",
       " 'tentacles',\n",
       " 'lovecraft',\n",
       " 'cool',\n",
       " 'cthulhu',\n",
       " 'gentleman',\n",
       " 'character',\n",
       " 'squid',\n",
       " 'animal',\n",
       " 'digital']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_tags[51961]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "product_vector_df = pd.DataFrame(product_data,columns=['tags', 'vector'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tags</th>\n",
       "      <th>vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[team, grunt, rocket, pokemon, uniform, villain]</td>\n",
       "      <td>[0.0550501, 0.0269306, 0.327811, -0.56768, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[toriyama, dbz, dub, 4kids, infinite, ball, ak...</td>\n",
       "      <td>[0.142125, 0.114305, 0.505677, 0.102514, 0.023...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[davinci, cute, tv, geek, cartoons, pikachu, p...</td>\n",
       "      <td>[-0.00838749, 0.0472564, 0.324731, -0.293568, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[red, evolution, starter, fire, pokemon]</td>\n",
       "      <td>[-0.00421771, 0.251726, 0.239894, -0.423287, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[cute, funny, nightfury, train, geek, cool, ve...</td>\n",
       "      <td>[0.216137, -0.0235948, 0.450602, -0.337562, -0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                tags  \\\n",
       "0   [team, grunt, rocket, pokemon, uniform, villain]   \n",
       "1  [toriyama, dbz, dub, 4kids, infinite, ball, ak...   \n",
       "2  [davinci, cute, tv, geek, cartoons, pikachu, p...   \n",
       "3           [red, evolution, starter, fire, pokemon]   \n",
       "4  [cute, funny, nightfury, train, geek, cool, ve...   \n",
       "\n",
       "                                              vector  \n",
       "0  [0.0550501, 0.0269306, 0.327811, -0.56768, 0.0...  \n",
       "1  [0.142125, 0.114305, 0.505677, 0.102514, 0.023...  \n",
       "2  [-0.00838749, 0.0472564, 0.324731, -0.293568, ...  \n",
       "3  [-0.00421771, 0.251726, 0.239894, -0.423287, 0...  \n",
       "4  [0.216137, -0.0235948, 0.450602, -0.337562, -0...  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_vector_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99450, 2)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_vector_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nsearch_query_tags = []\\nwith open(\\'user_search_keywords.tsv\\') as searchFile:\\n    searches = searchFile.readlines()\\n    for search in searches[1:]:\\n        if search.isspace() is False:\\n            tags = search.split(\"\\t\")[1]\\n            tags = tags.replace(\"\\n\", \"\").replace(\"\"\", \"\")\\n            tags = tags.split(\",\")\\n            b = []\\n            [generate_n_gram_tokens(tag) for tag in tags]\\n            search_query_tags.append(list(set(b)))\\n            #print(search_query_tags)\\n'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "search_query_tags = []\n",
    "with open('user_search_keywords.tsv') as searchFile:\n",
    "    searches = searchFile.readlines()\n",
    "    for search in searches[1:]:\n",
    "        if search.isspace() is False:\n",
    "            tags = search.split(\"\\t\")[1]\n",
    "            tags = tags.replace(\"\\n\", \"\").replace(\"\\\"\", \"\")\n",
    "            tags = tags.split(\",\")\n",
    "            b = []\n",
    "            [generate_n_gram_tokens(tag) for tag in tags]\n",
    "            search_query_tags.append(list(set(b)))\n",
    "            #print(search_query_tags)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words_in_vocab = set(w2v.index2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_cosine_similarity(row, search_vector):\n",
    "    try:\n",
    "        cosine_similarity = np.dot(row['vector'], search_vector)/linalg.norm(row['vector'])/linalg.norm(search_vector)\n",
    "        return cosine_similarity\n",
    "    except Exception as e:\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "search_query = ['hello', 'cat', 'dog', 'monkey', 'dbz' , 'dragon' , 'goku']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    search_vector = np.zeros((100,), dtype=\"float32\")\n",
    "    for tag in search_query:\n",
    "        if tag in words_in_vocab:\n",
    "            search_vector = np.add(search_vector, w2v[tag])\n",
    "    product_vector_df['cosine_similarity'] = product_vector_df.apply(get_cosine_similarity, axis=1, \n",
    "                                                                     args=(search_vector,))               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nischalhp/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:1: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "df = product_vector_df.sort(columns='cosine_similarity', ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tags</th>\n",
       "      <th>vector</th>\n",
       "      <th>cosine_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11288</th>\n",
       "      <td>[dbz, silhouette, monkey, super, negative, gok...</td>\n",
       "      <td>[0.187375, 0.0217866, 0.501207, 0.0109512, 0.0...</td>\n",
       "      <td>0.877507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>[grandpa, dbz, toriyama, nostalgic, gt, goku, ...</td>\n",
       "      <td>[0.349225, 0.0458218, 0.541412, 0.00121609, -0...</td>\n",
       "      <td>0.873349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45321</th>\n",
       "      <td>[toriyama, dbz, design, amazing, gt, goku, say...</td>\n",
       "      <td>[0.176304, 0.0117984, 0.536176, 0.0928079, -0....</td>\n",
       "      <td>0.870478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681</th>\n",
       "      <td>[gt, cloud, dragonball, goku, pikachu, pokemon...</td>\n",
       "      <td>[0.162702, 0.0341797, 0.831281, 0.118771, 0.27...</td>\n",
       "      <td>0.864560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3570</th>\n",
       "      <td>[kameha, dbz, power, 9000, dragon, goku, anime...</td>\n",
       "      <td>[0.180594, 0.0332023, 0.425862, 0.124274, 0.18...</td>\n",
       "      <td>0.863071</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    tags  \\\n",
       "11288  [dbz, silhouette, monkey, super, negative, gok...   \n",
       "710    [grandpa, dbz, toriyama, nostalgic, gt, goku, ...   \n",
       "45321  [toriyama, dbz, design, amazing, gt, goku, say...   \n",
       "681    [gt, cloud, dragonball, goku, pikachu, pokemon...   \n",
       "3570   [kameha, dbz, power, 9000, dragon, goku, anime...   \n",
       "\n",
       "                                                  vector  cosine_similarity  \n",
       "11288  [0.187375, 0.0217866, 0.501207, 0.0109512, 0.0...           0.877507  \n",
       "710    [0.349225, 0.0458218, 0.541412, 0.00121609, -0...           0.873349  \n",
       "45321  [0.176304, 0.0117984, 0.536176, 0.0928079, -0....           0.870478  \n",
       "681    [0.162702, 0.0341797, 0.831281, 0.118771, 0.27...           0.864560  \n",
       "3570   [0.180594, 0.0332023, 0.425862, 0.124274, 0.18...           0.863071  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[{\"tags\":[\"dbz\",\"silhouette\",\"monkey\",\"super\",\"negative\",\"goku\",\"vegetal\",\"manga\",\"space\",\"anime\",\"dragon\",\"saiyan\",\"ball\",\"cartoon\",\"gohan\",\"moon\"],\"cosine_similarity\":0.877506697},{\"tags\":[\"grandpa\",\"dbz\",\"toriyama\",\"nostalgic\",\"gt\",\"goku\",\"anime\",\"dragon\",\"ball\",\"gohan\",\"comics\",\"manga\",\"fanart\",\"dragonballz\",\"dragonball\",\"akira\",\"db\",\"son\",\"paper\",\"grandson\",\"kid\",\"baby\",\"nostalgia\"],\"cosine_similarity\":0.8733491791},{\"tags\":[\"toriyama\",\"dbz\",\"design\",\"amazing\",\"gt\",\"goku\",\"sayain\",\"art\",\"anime\",\"trunks\",\"dragon\",\"pokemon\",\"ball\",\"gohan\",\"shirt\",\"tee\",\"ssj2\",\"series\",\"television\",\"circle\",\"goten\",\"vageta\",\"super\",\"akira\",\"cartoon\",\"db\",\"tv\",\"awesome\",\"corallo\",\"drawing\"],\"cosine_similarity\":0.8704779067},{\"tags\":[\"gt\",\"cloud\",\"dragonball\",\"goku\",\"pikachu\",\"pokemon\",\"dragon\",\"ball\"],\"cosine_similarity\":0.8645601717},{\"tags\":[\"kameha\",\"dbz\",\"power\",\"9000\",\"dragon\",\"goku\",\"anime\",\"sayian\",\"ball\",\"crimson\",\"west\"],\"cosine_similarity\":0.8630713196},{\"tags\":[\"dbz\",\"dragon\",\"goku\",\"kid\",\"ball\",\"nimbus\"],\"cosine_similarity\":0.8629111325},{\"tags\":[\"dbz\",\"dragon\",\"goku\",\"anime\",\"piccolo\",\"ball\",\"cartoon\",\"fight\",\"shock\"],\"cosine_similarity\":0.860956098},{\"tags\":[\"dbz\",\"zlogo\",\"dragonball\",\"goku\",\"dragon\",\"ball\",\"cartoon\",\"gohan\"],\"cosine_similarity\":0.8598998442},{\"tags\":[\"toriyama\",\"son\",\"akira\",\"goku\",\"dragon\",\"ball\"],\"cosine_similarity\":0.8577463866},{\"tags\":[\"toriyama\",\"dbz\",\"akira\",\"evolution\",\"charles\",\"perfect\",\"goku\",\"manga\",\"anime\",\"frieza\",\"dragon\",\"darwin\",\"cell\",\"ball\",\"imperfect\"],\"cosine_similarity\":0.8554710082}]'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['tags','cosine_similarity']].to_json(orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
